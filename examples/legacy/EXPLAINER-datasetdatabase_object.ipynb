{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dsdb.DatasetDatabase\n",
    "\n",
    "### What is it?\n",
    "A dataset database is an object you will create to ingest, query, and process all types of datasets. This is the core of dsdb and has quite a lot built in to help you both run algorithms across datasets and version the inputs and results properly, but additionally it has built-in functions to help share you datasets with relative ease.\n",
    "\n",
    "### Why use it?\n",
    "The basics of why to use it is that it can handle any arbitrary datatypes with relative ease while providing a nice versioning and processing system on the backend for you. It can set up an entire database relatively quickly with little admin overhead. It handles type and value checking on ingestion, provides custom module support for your own file management systems, and much more!\n",
    "\n",
    "### Index\n",
    "1) [Initialization](#Initialization)\n",
    "\n",
    "2) [Uploading](#Uploading)\n",
    "\n",
    "3) [Querying](#Querying)\n",
    "\n",
    "4) [Processing](#Processing)\n",
    "\n",
    "5) [Sharing](#Sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Below is a good minimalistic way to connect to a dataset database object.\n",
    "\n",
    "**Note: If you haven't already, now is a good time to look over [the connect manager explainer](EXPLAINER-connection_manager.ipynb).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCAL:\n",
       "\tdriver: sqlite\n",
       "\tlink: /active/examples/local_database/local.db"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and connect to a connection manager instance\n",
    "import datasetdatabase as dsdb\n",
    "mngr = dsdb.ConnectionManager(user=\"jacksonb\")\n",
    "mngr.add_connections(dsdb.LOCAL)\n",
    "mngr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recent Datasets:\n",
       "--------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to local\n",
    "local = mngr.connect(dsdb.LOCAL)\n",
    "local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it. You now have a local instance of a dataset database. Local instances by default use sqlite as their driver. (However this shouldn't matter as dsdb handles interactions the same way regardless of database driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading\n",
    "\n",
    "Great, you have connected to a dataset database and you want to add a dataset to the database. Let's do just that. I will explain the nuances as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bools</th>\n",
       "      <th>files</th>\n",
       "      <th>floats</th>\n",
       "      <th>ndarrays</th>\n",
       "      <th>sets</th>\n",
       "      <th>strings</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>fp_example/0.json</td>\n",
       "      <td>74.004970</td>\n",
       "      <td>[[0.26331501518513467, 0.5337393933802977], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo0</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>fp_example/1.json</td>\n",
       "      <td>3.342143</td>\n",
       "      <td>[[0.9569493362751168, 0.13720932135607644], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo1</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>fp_example/2.json</td>\n",
       "      <td>85.273554</td>\n",
       "      <td>[[0.002259233518513537, 0.5212260272202929], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo2</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>fp_example/3.json</td>\n",
       "      <td>16.071675</td>\n",
       "      <td>[[0.7645604503388788, 0.020809797952066167], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>fp_example/4.json</td>\n",
       "      <td>67.145265</td>\n",
       "      <td>[[0.4712297782500141, 0.8161682980460269], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo4</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>fp_example/5.json</td>\n",
       "      <td>32.756948</td>\n",
       "      <td>[[0.3346475291060558, 0.9780580790165189], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo5</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>fp_example/6.json</td>\n",
       "      <td>82.500925</td>\n",
       "      <td>[[0.40664030180666166, 0.4513084114213143], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo6</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>fp_example/7.json</td>\n",
       "      <td>96.259690</td>\n",
       "      <td>[[0.4192502702591062, 0.4240524465509987], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo7</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>fp_example/8.json</td>\n",
       "      <td>3.516826</td>\n",
       "      <td>[[0.08427266973184566, 0.7325206981419501], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo8</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>fp_example/9.json</td>\n",
       "      <td>22.085252</td>\n",
       "      <td>[[0.055019993340200135, 0.5232460707782919], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo9</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bools              files     floats  \\\n",
       "0   True  fp_example/0.json  74.004970   \n",
       "1  False  fp_example/1.json   3.342143   \n",
       "2  False  fp_example/2.json  85.273554   \n",
       "3  False  fp_example/3.json  16.071675   \n",
       "4   True  fp_example/4.json  67.145265   \n",
       "5  False  fp_example/5.json  32.756948   \n",
       "6  False  fp_example/6.json  82.500925   \n",
       "7   True  fp_example/7.json  96.259690   \n",
       "8   True  fp_example/8.json   3.516826   \n",
       "9   True  fp_example/9.json  22.085252   \n",
       "\n",
       "                                            ndarrays       sets strings  \\\n",
       "0  [[0.26331501518513467, 0.5337393933802977], [0...  {1, 2, 3}    foo0   \n",
       "1  [[0.9569493362751168, 0.13720932135607644], [0...  {1, 2, 3}    foo1   \n",
       "2  [[0.002259233518513537, 0.5212260272202929], [...  {1, 2, 3}    foo2   \n",
       "3  [[0.7645604503388788, 0.020809797952066167], [...  {1, 2, 3}    foo3   \n",
       "4  [[0.4712297782500141, 0.8161682980460269], [0....  {1, 2, 3}    foo4   \n",
       "5  [[0.3346475291060558, 0.9780580790165189], [0....  {1, 2, 3}    foo5   \n",
       "6  [[0.40664030180666166, 0.4513084114213143], [0...  {1, 2, 3}    foo6   \n",
       "7  [[0.4192502702591062, 0.4240524465509987], [0....  {1, 2, 3}    foo7   \n",
       "8  [[0.08427266973184566, 0.7325206981419501], [0...  {1, 2, 3}    foo8   \n",
       "9  [[0.055019993340200135, 0.5232460707782919], [...  {1, 2, 3}    foo9   \n",
       "\n",
       "      tuples  \n",
       "0  (1, 2, 3)  \n",
       "1  (1, 2, 3)  \n",
       "2  (1, 2, 3)  \n",
       "3  (1, 2, 3)  \n",
       "4  (1, 2, 3)  \n",
       "5  (1, 2, 3)  \n",
       "6  (1, 2, 3)  \n",
       "7  (1, 2, 3)  \n",
       "8  (1, 2, 3)  \n",
       "9  (1, 2, 3)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import to help us create a test dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# create a test dataset to upload that has various types of data\n",
    "fp_ex = pathlib.Path(\"./fp_example/\")\n",
    "if not fp_ex.exists():\n",
    "    os.makedirs(fp_ex)\n",
    "\n",
    "# for reproducibility I will set the seed here\n",
    "np.random.seed(seed=12)\n",
    "\n",
    "# creating lists of dicts to be formed into a dataframe\n",
    "test = []\n",
    "for i in range(10):\n",
    "    fp =  fp_ex / (str(i) + \".json\")\n",
    "    with open(fp, \"w\") as write_out:\n",
    "        json.dump({\"hello\": \"world\"}, write_out)\n",
    "    \n",
    "    d = {}\n",
    "    d[\"strings\"] = \"foo\" + str(i)\n",
    "    d[\"bools\"] = np.random.rand() < 0.5\n",
    "    d[\"floats\"] = np.random.rand() * 100\n",
    "    d[\"ndarrays\"] = np.random.rand(2, 2)\n",
    "    d[\"tuples\"] = tuple([1, 2, 3])\n",
    "    d[\"sets\"] = set([1, 2, 3, 3, 3])\n",
    "    d[\"files\"] = str(fp)\n",
    "    test.append(d)\n",
    "\n",
    "# convert this example both to dataframe\n",
    "test = pd.DataFrame(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Dataset...\n",
      "[============================================================] 100.0% (280/280) ~ 0:00:00 remaining\n",
      "Creating Iota...\n",
      "[============================================================] 100.0% (70/70) ~ 0:00:00 remaining\n",
      "Creating Junction Items...\n",
      "[============================================================] 100.0% (80/80) ~ 0:00:00 remaining\n",
      "Dataset upload complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DatasetId': 1,\n",
       " 'Name': 'test dataset',\n",
       " 'Description': 'this is the hello world of dataset ingestion',\n",
       " 'SourceId': 1,\n",
       " 'FilepathColumns': \"['files']\",\n",
       " 'Created': '2018-08-06 23:43:35.062186'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload and return the dataset info\n",
    "ds_info = local.upload_dataset(dataset=test,\n",
    "                               name=\"test dataset\",\n",
    "                               description=\"this is the hello world of dataset ingestion\",\n",
    "                               type_map={\"bools\": bool,\n",
    "                                         \"files\": str,\n",
    "                                         \"floats\": float,\n",
    "                                         \"ndarrays\": np.ndarray,\n",
    "                                         \"strings\": str},\n",
    "                               filepath_columns=[\"files\"])\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down what just happened, we first validated the dataset. Initially we take the md5 hash of the dataframe object, if we have already stored this md5 then no processing is done and the already stored dataset info is returned. If it is truly a new dataset (like this one is), we start checking that all filepaths exist given any columns labeled as filepaths, checking the dataset types given a map of columns to their types (this can even be a column to a list of approved types, ex: {\"files\": [str, pathlib.Path]}), and we didn't here but you can also specify checking functions for each columns using a \"value_validation_map\" such as {\"floats\": lambda x: return x < 100}. If we didn't specify which columns stored filepaths our fms would not store any files in it's storage and no files would be added to the files table. Additionally, if you leave the \"type_map\" as None, each value type is assumed correct. There is a lot to this one function so I recommend reading the function doc string for more information.\n",
    "\n",
    "A note on filepaths: any filepath found in the filepath columns will be deduplicated, meaning, if a file's md5 hash has already been encountered before it won't make create a new file in the fms.\n",
    "\n",
    "That was just the validation portion of the ingestion process. The next step shown is the \"Creating Iota\" process. This is how data is actually stored in the dataset database. We break down the dataframe is to key-value pairings and store them individually, this reduces the ammount of storage required by a bit as instead of saying each dataset is a unique item, it will most likely happen that some row-column pairings from one dataset were already contained in another. Creating Iota takes a while simply because a secondary part of breaking down each key-value pairing we also store all values as a string and store some metadata about that key-value pairing so that when you want to retrieve it, we can cast that pairing back to it's original form properly. Because this is the lowest possible form a key-value pairing can take we called them \"Iota\" or an extremely small amount of data.\n",
    "\n",
    "The last process is the \"Creating Junction Items\". This simply stitches all Iota that were creating to the dataset object that has also been created. We do this last because if at any point, anything went wrong, we can stop the process and not create a dataset.\n",
    "\n",
    "What was returned to was the dataset info, which you can use to retrieve, process, and share datasets by using the information stored in the returned dictionary with other dsdb functions.\n",
    "\n",
    "If we want to see the recent additions to all tables and not just the dataset table, you can run `dsdb._deep_print()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying\n",
    "\n",
    "You just uploaded a dataset, let's get it a back to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recent Datasets:\n",
       "--------------------------------------------------------------------------------\n",
       "{'DatasetId': 1, 'Name': 'test dataset', 'Description': 'this is the hello world of dataset ingestion', 'SourceId': 1, 'FilepathColumns': \"['files']\", 'Created': '2018-08-06 23:43:35.062186'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recent datasets\n",
    "local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bools</th>\n",
       "      <th>files</th>\n",
       "      <th>floats</th>\n",
       "      <th>ndarrays</th>\n",
       "      <th>sets</th>\n",
       "      <th>strings</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>74.004970</td>\n",
       "      <td>[[0.26331501518513467, 0.5337393933802977], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo0</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>3.342143</td>\n",
       "      <td>[[0.9569493362751168, 0.13720932135607644], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo1</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>85.273554</td>\n",
       "      <td>[[0.002259233518513537, 0.5212260272202929], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo2</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>16.071675</td>\n",
       "      <td>[[0.7645604503388788, 0.020809797952066167], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>67.145265</td>\n",
       "      <td>[[0.4712297782500141, 0.8161682980460269], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo4</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>32.756948</td>\n",
       "      <td>[[0.3346475291060558, 0.9780580790165189], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo5</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>82.500925</td>\n",
       "      <td>[[0.40664030180666166, 0.4513084114213143], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo6</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>96.259690</td>\n",
       "      <td>[[0.4192502702591062, 0.4240524465509987], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo7</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>3.516826</td>\n",
       "      <td>[[0.08427266973184566, 0.7325206981419501], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo8</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>22.085252</td>\n",
       "      <td>[[0.055019993340200135, 0.5232460707782919], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo9</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bools                                              files     floats  \\\n",
       "0   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...  74.004970   \n",
       "1  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   3.342143   \n",
       "2  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...  85.273554   \n",
       "3  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...  16.071675   \n",
       "4   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...  67.145265   \n",
       "5  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...  32.756948   \n",
       "6  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...  82.500925   \n",
       "7   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...  96.259690   \n",
       "8   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...   3.516826   \n",
       "9   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...  22.085252   \n",
       "\n",
       "                                            ndarrays       sets strings  \\\n",
       "0  [[0.26331501518513467, 0.5337393933802977], [0...  {1, 2, 3}    foo0   \n",
       "1  [[0.9569493362751168, 0.13720932135607644], [0...  {1, 2, 3}    foo1   \n",
       "2  [[0.002259233518513537, 0.5212260272202929], [...  {1, 2, 3}    foo2   \n",
       "3  [[0.7645604503388788, 0.020809797952066167], [...  {1, 2, 3}    foo3   \n",
       "4  [[0.4712297782500141, 0.8161682980460269], [0....  {1, 2, 3}    foo4   \n",
       "5  [[0.3346475291060558, 0.9780580790165189], [0....  {1, 2, 3}    foo5   \n",
       "6  [[0.40664030180666166, 0.4513084114213143], [0...  {1, 2, 3}    foo6   \n",
       "7  [[0.4192502702591062, 0.4240524465509987], [0....  {1, 2, 3}    foo7   \n",
       "8  [[0.08427266973184566, 0.7325206981419501], [0...  {1, 2, 3}    foo8   \n",
       "9  [[0.055019993340200135, 0.5232460707782919], [...  {1, 2, 3}    foo9   \n",
       "\n",
       "      tuples  \n",
       "0  (1, 2, 3)  \n",
       "1  (1, 2, 3)  \n",
       "2  (1, 2, 3)  \n",
       "3  (1, 2, 3)  \n",
       "4  (1, 2, 3)  \n",
       "5  (1, 2, 3)  \n",
       "6  (1, 2, 3)  \n",
       "7  (1, 2, 3)  \n",
       "8  (1, 2, 3)  \n",
       "9  (1, 2, 3)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local.get_dataset(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keep calm!**\n",
    "\n",
    "Yes, the filepaths look different, remember when I said in the above section that during Iota creation process dsdb handles the fms upload of any files in the columns listed as filepath columns? Well it also changes those filepaths to be the fms filepaths. We do this so we can guarantee a dataset will always be usable. As you can see by the filepaths, the default fms module is a [Quilt](https://quiltdata.com) backend. If you want to view the original dataset without any changes to the filepaths or data you can use the File and the dataset info that was passed back from the upload to track down the FMS readpath of the unchanged uploaded dataset. (For provenance we also versioned that for you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "When handling algorithms and functions, the system devised is that you will be processing a dataset. This in short means you algorithms/ methods/ functions will have two parameters, a dataset parameter which will be passed the recasted dataset from a `dsdb.get_dataset()` call, and then an \"other parameters\" keyword. Other parameters are options you pass using the `dsdb.process_run()` function under the `alg_parameters` keyword. In our example we won't be using these but having the keyword slot available is required (you can call these parameters whatever you would like). Additionally, your function must return a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_col(dataset, params):\n",
    "    dataset[params[\"col\"]] += params[\"add\"]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Dataset...\n",
      "[============================================================] 100.0% (280/280) ~ 0:00:00 remaining\n",
      "Creating Iota...\n",
      "[============================================================] 100.0% (70/70) ~ 0:00:00 remaining\n",
      "Creating Junction Items...\n",
      "[============================================================] 100.0% (80/80) ~ 0:00:00 remaining\n",
      "Dataset upload complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DatasetId': 2,\n",
       " 'Name': 'processing test',\n",
       " 'Description': 'this is an example of processing a dataset',\n",
       " 'SourceId': 2,\n",
       " 'FilepathColumns': \"['files']\",\n",
       " 'Created': '2018-08-06 23:43:38.041504'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process the original dataset\n",
    "# using the function provided\n",
    "# stored the processed dataset info\n",
    "post_process_info = local.process_run(add_to_col,\n",
    "                                      ds_info[\"DatasetId\"],\n",
    "                                      alg_parameters={\"col\": \"floats\", \"add\": 12},\n",
    "                                      dataset_parameters={\"name\": \"processing test\",\n",
    "                                                          \"description\": \"this is an example of processing a dataset\",\n",
    "                                                          \"filepath_columns\": \"files\"})\n",
    "post_process_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bools</th>\n",
       "      <th>files</th>\n",
       "      <th>floats</th>\n",
       "      <th>ndarrays</th>\n",
       "      <th>sets</th>\n",
       "      <th>strings</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>86.004970</td>\n",
       "      <td>[[0.26331501518513467, 0.5337393933802977], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo0</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>15.342143</td>\n",
       "      <td>[[0.9569493362751168, 0.13720932135607644], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo1</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>97.273554</td>\n",
       "      <td>[[0.002259233518513537, 0.5212260272202929], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo2</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>28.071675</td>\n",
       "      <td>[[0.7645604503388788, 0.020809797952066167], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>79.145265</td>\n",
       "      <td>[[0.4712297782500141, 0.8161682980460269], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo4</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>44.756948</td>\n",
       "      <td>[[0.3346475291060558, 0.9780580790165189], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo5</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>94.500925</td>\n",
       "      <td>[[0.40664030180666166, 0.4513084114213143], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo6</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>108.259690</td>\n",
       "      <td>[[0.4192502702591062, 0.4240524465509987], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo7</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>15.516826</td>\n",
       "      <td>[[0.08427266973184566, 0.7325206981419501], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo8</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>/home/jovyan/.local/share/QuiltCli/quilt_packa...</td>\n",
       "      <td>34.085252</td>\n",
       "      <td>[[0.055019993340200135, 0.5232460707782919], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo9</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bools                                              files      floats  \\\n",
       "0   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...   86.004970   \n",
       "1  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   15.342143   \n",
       "2  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   97.273554   \n",
       "3  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   28.071675   \n",
       "4   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...   79.145265   \n",
       "5  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   44.756948   \n",
       "6  False  /home/jovyan/.local/share/QuiltCli/quilt_packa...   94.500925   \n",
       "7   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...  108.259690   \n",
       "8   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...   15.516826   \n",
       "9   True  /home/jovyan/.local/share/QuiltCli/quilt_packa...   34.085252   \n",
       "\n",
       "                                            ndarrays       sets strings  \\\n",
       "0  [[0.26331501518513467, 0.5337393933802977], [0...  {1, 2, 3}    foo0   \n",
       "1  [[0.9569493362751168, 0.13720932135607644], [0...  {1, 2, 3}    foo1   \n",
       "2  [[0.002259233518513537, 0.5212260272202929], [...  {1, 2, 3}    foo2   \n",
       "3  [[0.7645604503388788, 0.020809797952066167], [...  {1, 2, 3}    foo3   \n",
       "4  [[0.4712297782500141, 0.8161682980460269], [0....  {1, 2, 3}    foo4   \n",
       "5  [[0.3346475291060558, 0.9780580790165189], [0....  {1, 2, 3}    foo5   \n",
       "6  [[0.40664030180666166, 0.4513084114213143], [0...  {1, 2, 3}    foo6   \n",
       "7  [[0.4192502702591062, 0.4240524465509987], [0....  {1, 2, 3}    foo7   \n",
       "8  [[0.08427266973184566, 0.7325206981419501], [0...  {1, 2, 3}    foo8   \n",
       "9  [[0.055019993340200135, 0.5232460707782919], [...  {1, 2, 3}    foo9   \n",
       "\n",
       "      tuples  \n",
       "0  (1, 2, 3)  \n",
       "1  (1, 2, 3)  \n",
       "2  (1, 2, 3)  \n",
       "3  (1, 2, 3)  \n",
       "4  (1, 2, 3)  \n",
       "5  (1, 2, 3)  \n",
       "6  (1, 2, 3)  \n",
       "7  (1, 2, 3)  \n",
       "8  (1, 2, 3)  \n",
       "9  (1, 2, 3)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the processed dataset\n",
    "local.get_dataset(post_process_info[\"DatasetId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The two rather imporant keyword arguments to think about passing to `dsdb.process_run()` are alg_parameters as mentioned before and dataset_parameters.**\n",
    "\n",
    "\"alg_parameters\" are passed to the algorithm/ function/ method and you can then do what you want with them.\n",
    "\n",
    "\"dataset_parameters\" are used by the dataset creation function and have the exact same keywords available as that of the `dsdb.upload_dataset()` function except for dataset. (name, description, type_map, value_validation_map, import_as_type_map, store_files, force_storage, filepath_columns, and replace_paths). These dataset parameters will be used on the returned dataset upload process meaning if you make a brand new dataframe with different column names, use these new column names in your type_map, filepath_columns, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing\n",
    "\n",
    "You can also share you datasets relatively easily due to the builtin quilt backend. Simply pass a dataset id to the `dsdb.export_to_quilt()` function and it will create a Quilt package and return the package name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dsdb/processing_test'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export/ create the processed dataset\n",
    "local.export_to_quilt(post_process_info[\"DatasetId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PackageNode>\n",
       "files/\n",
       "README\n",
       "data"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quilt.data.dsdb import processing_test\n",
    "processing_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing test:\n",
      "\n",
      "## Description:\n",
      "this is an example of processing a dataset\n",
      "\n",
      "## Filepath Columns:\n",
      "['files']\n",
      "\n",
      "## Created:\n",
      "2018-08-06 23:43:38.041504\n",
      "\n",
      "## Origin SourceId:\n",
      "2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comes with a generated readme\n",
    "readme = processing_test.README()\n",
    "readme = open(readme, \"r\")\n",
    "print(readme.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bools</th>\n",
       "      <th>files</th>\n",
       "      <th>floats</th>\n",
       "      <th>ndarrays</th>\n",
       "      <th>sets</th>\n",
       "      <th>strings</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>json_2</td>\n",
       "      <td>86.004970</td>\n",
       "      <td>[[0.26331501518513467, 0.5337393933802977], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo0</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>json_2</td>\n",
       "      <td>15.342143</td>\n",
       "      <td>[[0.9569493362751168, 0.13720932135607644], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo1</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>json_2</td>\n",
       "      <td>97.273554</td>\n",
       "      <td>[[0.002259233518513537, 0.5212260272202929], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo2</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>json_2</td>\n",
       "      <td>28.071675</td>\n",
       "      <td>[[0.7645604503388788, 0.020809797952066167], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>json_2</td>\n",
       "      <td>79.145265</td>\n",
       "      <td>[[0.4712297782500141, 0.8161682980460269], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo4</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>json_2</td>\n",
       "      <td>44.756948</td>\n",
       "      <td>[[0.3346475291060558, 0.9780580790165189], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo5</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>json_2</td>\n",
       "      <td>94.500925</td>\n",
       "      <td>[[0.40664030180666166, 0.4513084114213143], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo6</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>json_2</td>\n",
       "      <td>108.259690</td>\n",
       "      <td>[[0.4192502702591062, 0.4240524465509987], [0....</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo7</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>json_2</td>\n",
       "      <td>15.516826</td>\n",
       "      <td>[[0.08427266973184566, 0.7325206981419501], [0...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo8</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>json_2</td>\n",
       "      <td>34.085252</td>\n",
       "      <td>[[0.055019993340200135, 0.5232460707782919], [...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>foo9</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bools   files      floats  \\\n",
       "0   True  json_2   86.004970   \n",
       "1  False  json_2   15.342143   \n",
       "2  False  json_2   97.273554   \n",
       "3  False  json_2   28.071675   \n",
       "4   True  json_2   79.145265   \n",
       "5  False  json_2   44.756948   \n",
       "6  False  json_2   94.500925   \n",
       "7   True  json_2  108.259690   \n",
       "8   True  json_2   15.516826   \n",
       "9   True  json_2   34.085252   \n",
       "\n",
       "                                            ndarrays       sets strings  \\\n",
       "0  [[0.26331501518513467, 0.5337393933802977], [0...  {1, 2, 3}    foo0   \n",
       "1  [[0.9569493362751168, 0.13720932135607644], [0...  {1, 2, 3}    foo1   \n",
       "2  [[0.002259233518513537, 0.5212260272202929], [...  {1, 2, 3}    foo2   \n",
       "3  [[0.7645604503388788, 0.020809797952066167], [...  {1, 2, 3}    foo3   \n",
       "4  [[0.4712297782500141, 0.8161682980460269], [0....  {1, 2, 3}    foo4   \n",
       "5  [[0.3346475291060558, 0.9780580790165189], [0....  {1, 2, 3}    foo5   \n",
       "6  [[0.40664030180666166, 0.4513084114213143], [0...  {1, 2, 3}    foo6   \n",
       "7  [[0.4192502702591062, 0.4240524465509987], [0....  {1, 2, 3}    foo7   \n",
       "8  [[0.08427266973184566, 0.7325206981419501], [0...  {1, 2, 3}    foo8   \n",
       "9  [[0.055019993340200135, 0.5232460707782919], [...  {1, 2, 3}    foo9   \n",
       "\n",
       "      tuples  \n",
       "0  (1, 2, 3)  \n",
       "1  (1, 2, 3)  \n",
       "2  (1, 2, 3)  \n",
       "3  (1, 2, 3)  \n",
       "4  (1, 2, 3)  \n",
       "5  (1, 2, 3)  \n",
       "6  (1, 2, 3)  \n",
       "7  (1, 2, 3)  \n",
       "8  (1, 2, 3)  \n",
       "9  (1, 2, 3)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the dataset\n",
    "read_in = pd.read_pickle(processing_test.data())\n",
    "read_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<GroupNode>\n",
       "json_2/"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only one file because all the json files were the same {\"hello\": \"world\"}\n",
    "processing_test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n",
      "{'hello': 'world'}\n"
     ]
    }
   ],
   "source": [
    "# open all files\n",
    "for f in read_in[\"files\"]:\n",
    "    fp = getattr(processing_test.files, f)\n",
    "    print(json.load(open(fp.load())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2)),\n",
       " (numpy.ndarray, (2, 2))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show that types were conserved even through export\n",
    "[(type(nd), nd.shape) for nd in read_in[\"ndarrays\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using the package outside of a dataset database is easy enough, there is also a `dsdb.import_from_quilt()` function if your collaborators are also using this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teardown the database and supporting files so we know we will get a fresh dsdb instance\n",
    "import shutil\n",
    "shutil.rmtree(fp_ex)\n",
    "db_store = pathlib.Path(\"/active/examples/local_database/\")\n",
    "shutil.rmtree(db_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------- DATASET DATABASE -------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Recent User:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Iota:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Source:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent FileSource:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent QuiltSource:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent IotaDatasetJunction:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Algorithm:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent Run:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent RunInput:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent RunOutput:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent RunSource:\n",
      "--------------------------------------------------------------------------------\n",
      "Recent File:\n"
     ]
    }
   ],
   "source": [
    "# rebuild and display empty database\n",
    "mngr = dsdb.ConnectionManager(dsdb.LOCAL, user=\"jacksonb\")\n",
    "local = mngr.connect(dsdb.LOCAL)\n",
    "local._deep_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Dataset...\n",
      "[============================================================] 100.0% (280/280) ~ 0:00:00 remaining\n",
      "Creating Iota...\n",
      "[============================================================] 100.0% (70/70) ~ 0:00:00 remaining\n",
      "Creating Junction Items...\n",
      "[============================================================] 100.0% (80/80) ~ 0:00:00 remaining\n",
      "Dataset upload complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DatasetId': 1,\n",
       " 'Name': 'dsdb/processing_test',\n",
       " 'Description': 'this is an example of processing a dataset',\n",
       " 'SourceId': 1,\n",
       " 'FilepathColumns': \"['files']\",\n",
       " 'Created': '2018-08-06 23:43:41.788372'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local.import_from_quilt(\"dsdb/processing_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recent Datasets:\n",
       "--------------------------------------------------------------------------------\n",
       "{'DatasetId': 1, 'Name': 'dsdb/processing_test', 'Description': 'this is an example of processing a dataset', 'SourceId': 1, 'FilepathColumns': \"['files']\", 'Created': '2018-08-06 23:43:41.788372'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "There is more to come for Dataset Database but this covers much of the basics of uploading, querying, and processing data. Please point all issues you have at the [GitHub issues page](https://github.com/AllenCellModeling/aics_modeling_db/issues) for this repo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
